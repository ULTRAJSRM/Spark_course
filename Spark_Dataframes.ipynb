{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframes\n",
    "**By Jorge S. Ruiz**\n",
    " - This is an introduction about how to use Dataframes in Spark.\n",
    " - Dataframes can be used as SQL tables.\n",
    " - Dataframes have better optimization because they use Catalyst as query optimization and Tugsten as execution engine.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a dataframe from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Libraries for Datatypes (dataframes)\n",
    "from pyspark.sql.types import StructType, StructField \n",
    "from pyspark.sql.types import IntegerType, StringType, FloatType\n",
    "from pyspark.sql.types import Row\n",
    "\n",
    "# Library for SQL\n",
    "from pyspark.sql import SQLContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing Spark\n",
    "spark = SparkContext(master='local', appName='Dataframes')\n",
    "# Initializing SQL Context\n",
    "sqlContext = SQLContext(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deporte.csv\t deportistaError.csv  modelo_relacional.jpg\n",
      "deportista2.csv  evento.csv\t      paises.csv\n",
      "deportista.csv\t juegos.csv\t      resultados.csv\n"
     ]
    }
   ],
   "source": [
    "!ls /home/lastorder/Documents/curso-apache-spark-platzi/files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",nombre_juego,annio,temporada,ciudad\n",
      "1,1896 Verano,1896,Verano,Athina\n",
      "2,1900 Verano,1900,Verano,Paris\n",
      "3,1904 Verano,1904,Verano,St. Louis\n"
     ]
    }
   ],
   "source": [
    "# Linux command to check the file content\n",
    "!head -n 4 /home/lastorder/Documents/curso-apache-spark-platzi/files/juegos.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the PATH to csv files.\n",
    "path = '/home/lastorder/Documents/curso-apache-spark-platzi/files/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to create a schema with the information of the columns:\n",
    "# Struct file helpus to indicate the parameters of the columns of the DF\n",
    "# The fields are, name of the column, datatype and if the column is an optional field.\n",
    "# False indicates that the column is a necessary field and true indicates that is optional.\n",
    "\n",
    "gameSchema = StructType([\n",
    "    StructField('game_id',IntegerType(),False),\n",
    "    StructField('year',StringType(),False),\n",
    "    StructField('season',StringType(),False),\n",
    "    StructField('city',StringType(),False)\n",
    "])\n",
    "\n",
    "# Now we can create the dataframe using our previous Schema.\n",
    "\n",
    "gameDF = sqlContext.read.schema(gameSchema).option('header','true') \\\n",
    "    .csv(path+'juegos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+------+--------+\n",
      "|game_id|         year|season|    city|\n",
      "+-------+-------------+------+--------+\n",
      "|      1|  1896 Verano|  1896|  Verano|\n",
      "|      2|  1900 Verano|  1900|  Verano|\n",
      "|      3|  1904 Verano|  1904|  Verano|\n",
      "|      4|  1906 Verano|  1906|  Verano|\n",
      "|      5|  1908 Verano|  1908|  Verano|\n",
      "|      6|  1912 Verano|  1912|  Verano|\n",
      "|      7|  1920 Verano|  1920|  Verano|\n",
      "|      8|1924 Invierno|  1924|Invierno|\n",
      "|      9|  1924 Verano|  1924|  Verano|\n",
      "|     10|1928 Invierno|  1928|Invierno|\n",
      "+-------+-------------+------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In dataframes we can use \"show\" to obtain a better data visualization\n",
    "gameDF.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.66:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Dataframes</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local appName=Dataframes>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To access to Spark UI console, we use just \"spark\" command and click on Spark UI\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Extract from RDDs Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting 2 RDDs, the first one contains the header and the second one contains the data.\n",
    "OlimpicAthleteRDD = spark.textFile(path+'deportista.csv').map(lambda l : l.split(','))\n",
    "OlimpicAthleteRDD2 = spark.textFile(path+'deportista2.csv').map(lambda l : l.split(','))\n",
    "\n",
    "# To make a union between the RDDs we can use:\n",
    "OlimpicAthleteRDD = OlimpicAthleteRDD.union(OlimpicAthleteRDD2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135572"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To make sure that the data is not corrupted, we can use count() to verify that spark is working correctly\n",
    "# with that data\n",
    "OlimpicAthleteRDD.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['deportista_id', 'nombre', 'genero', 'edad', 'altura', 'peso', 'equipo_id'],\n",
       " ['1', 'A Dijiang', '1', '24', '180', '80', '199'],\n",
       " ['2', 'A Lamusi', '1', '23', '170', '60', '199'],\n",
       " ['3', 'Gunnar Nielsen Aaby', '1', '24', '0', '0', '273'],\n",
       " ['4', 'Edgar Lindenau Aabye', '1', '34', '0', '0', '278']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see the first 10 rows of the RDD, we use top function (similar to SQL)\n",
    "OlimpicAthleteRDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the header of the RDD\n",
    "# 'iter' function, returns all values of we process in the function\n",
    "\n",
    "def removeHeader(index, iterator):\n",
    "    \"\"\"A fuction that removes the header from a dataset or RDD\"\"\"\n",
    "    return iter(list(iterator)[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We map the RDD assigning a index (this maps rows and columns per index)\n",
    "# Now we can use a function that will take action in all rows and columns on the RDD.\n",
    "OlimpicAthleteRDD_clean = OlimpicAthleteRDD.mapPartitionsWithIndex(removeHeader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', 'A Dijiang', '1', '24', '180', '80', '199'],\n",
       " ['2', 'A Lamusi', '1', '23', '170', '60', '199'],\n",
       " ['3', 'Gunnar Nielsen Aaby', '1', '24', '0', '0', '273'],\n",
       " ['4', 'Edgar Lindenau Aabye', '1', '34', '0', '0', '278'],\n",
       " ['5', 'Christine Jacoba Aaftink', '2', '21', '185', '82', '705']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see if the header is gone\n",
    "OlimpicAthleteRDD_clean.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To transform the values of the RDD\n",
    "# For that we are goint to make a mapping\n",
    "\n",
    "OlimpicAthleteRDD_clean = OlimpicAthleteRDD_clean.map(lambda l: (\n",
    "    int(l[0]),\n",
    "    l[1],\n",
    "    int(l[2]),\n",
    "    int(l[3]),\n",
    "    int(l[4]),\n",
    "    float(l[5]),\n",
    "    int(l[6])    \n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We ned to define a new Schema:\n",
    "\n",
    "schema = StructType([\n",
    "    StructField('athlete_id', IntegerType(),False),\n",
    "    StructField('name', StringType(),False),\n",
    "    StructField('gender', IntegerType(),False),\n",
    "    StructField('age', IntegerType(),False),\n",
    "    StructField('height', IntegerType(),False),\n",
    "    StructField('weight', FloatType(),False),\n",
    "    StructField('team_id', IntegerType(),False),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe with sqlContext, using an existing RDD and a Schema\n",
    "AthleteDF = sqlContext.createDataFrame(OlimpicAthleteRDD_clean, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+------+---+------+------+-------+\n",
      "|athlete_id|                name|gender|age|height|weight|team_id|\n",
      "+----------+--------------------+------+---+------+------+-------+\n",
      "|         1|           A Dijiang|     1| 24|   180|  80.0|    199|\n",
      "|         2|            A Lamusi|     1| 23|   170|  60.0|    199|\n",
      "|         3| Gunnar Nielsen Aaby|     1| 24|     0|   0.0|    273|\n",
      "|         4|Edgar Lindenau Aabye|     1| 34|     0|   0.0|    278|\n",
      "|         5|Christine Jacoba ...|     2| 21|   185|  82.0|    705|\n",
      "|         6|     Per Knut Aaland|     1| 31|   188|  75.0|   1096|\n",
      "|         7|        John Aalberg|     1| 31|   183|  72.0|   1096|\n",
      "|         8|Cornelia Cor Aalt...|     2| 18|   168|   0.0|    705|\n",
      "|         9|    Antti Sami Aalto|     1| 26|   186|  96.0|    350|\n",
      "|        10|Einar Ferdinand E...|     1| 26|     0|   0.0|    350|\n",
      "+----------+--------------------+------+---+------+------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To prove everything is correct with our new DF, we can use show function\n",
    "AthleteDF.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(athlete_id=1, name='A Dijiang', gender=1, age=24, height=180, weight=80.0, team_id=199),\n",
       " Row(athlete_id=2, name='A Lamusi', gender=1, age=23, height=170, weight=60.0, team_id=199),\n",
       " Row(athlete_id=3, name='Gunnar Nielsen Aaby', gender=1, age=24, height=0, weight=0.0, team_id=273),\n",
       " Row(athlete_id=4, name='Edgar Lindenau Aabye', gender=1, age=34, height=0, weight=0.0, team_id=278),\n",
       " Row(athlete_id=5, name='Christine Jacoba Aaftink', gender=2, age=21, height=185, weight=82.0, team_id=705),\n",
       " Row(athlete_id=6, name='Per Knut Aaland', gender=1, age=31, height=188, weight=75.0, team_id=1096),\n",
       " Row(athlete_id=7, name='John Aalberg', gender=1, age=31, height=183, weight=72.0, team_id=1096),\n",
       " Row(athlete_id=8, name='Cornelia Cor Aalten Strannood ', gender=2, age=18, height=168, weight=0.0, team_id=705),\n",
       " Row(athlete_id=9, name='Antti Sami Aalto', gender=1, age=26, height=186, weight=96.0, team_id=350),\n",
       " Row(athlete_id=10, name='Einar Ferdinand Einari Aalto', gender=1, age=26, height=0, weight=0.0, team_id=350)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see the explicit values without format we use \"take\" function\n",
    "AthleteDF.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating another Dataframe from RDD\n",
    "CountriesRDD = spark.textFile(path+\"paises.csv\")\\\n",
    "    .map(lambda line : line.split(\",\"))\n",
    "\n",
    "CountriesRDD = CountriesRDD.mapPartitionsWithIndex(removeHeader)\n",
    "\n",
    "\n",
    "CountriesRDD = CountriesRDD.map(lambda l: (\n",
    "    int(l[0]),\n",
    "    l[1],\n",
    "    l[2]\n",
    "))\n",
    "\n",
    "CountriesSchema = StructType([\n",
    "    StructField('team_id', IntegerType(),False),\n",
    "    StructField('team_name', StringType(),False),\n",
    "    StructField('country_name', StringType(),False)\n",
    "])\n",
    "\n",
    "CountriesDF = sqlContext.createDataFrame(CountriesRDD, CountriesSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------------+\n",
      "|team_id|           team_name|country_name|\n",
      "+-------+--------------------+------------+\n",
      "|      1|         30. Februar|         AUT|\n",
      "|      2|A North American ...|         MEX|\n",
      "|      3|           Acipactli|         MEX|\n",
      "|      4|             Acturus|         ARG|\n",
      "|      5|         Afghanistan|         AFG|\n",
      "|      6|            Akatonbo|         IRL|\n",
      "|      7|            Alain IV|         SUI|\n",
      "|      8|             Albania|         ALB|\n",
      "|      9|              Alcaid|         POR|\n",
      "|     10|            Alcyon-6|         FRA|\n",
      "+-------+--------------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CountriesDF.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Dataframefrom csv with a schema (without using an RDD)\n",
    "OlympicSportsRDDSchema = StructType([\n",
    "    StructField('sport_id', IntegerType(),False),\n",
    "    StructField('sport_name', StringType(),False)\n",
    "])\n",
    "\n",
    "sportsDF = sqlContext.read.schema(OlympicSportsRDDSchema).option('header','true') \\\n",
    "    .csv(path+'deporte.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|sport_id|          sport_name|\n",
      "+--------+--------------------+\n",
      "|       1|          Basketball|\n",
      "|       2|                Judo|\n",
      "|       3|            Football|\n",
      "|       4|          Tug-Of-War|\n",
      "|       5|       Speed Skating|\n",
      "|       6|Cross Country Skiing|\n",
      "|       7|           Athletics|\n",
      "|       8|          Ice Hockey|\n",
      "|       9|            Swimming|\n",
      "|      10|           Badminton|\n",
      "+--------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sportsDF.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the same way, we can create as many datasets as we want.\n",
    "# All we need is to define an schema and import the csv file.\n",
    "EventsRDDSchema = StructType([\n",
    "    StructField('event_id', IntegerType(),False),\n",
    "    StructField('event_name', StringType(),False),\n",
    "    StructField('sport_id', IntegerType(),False)\n",
    "])\n",
    "\n",
    "OlympicEventsDF = sqlContext.read.schema(EventsRDDSchema).option('header','true') \\\n",
    "    .csv(path+'evento.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------+\n",
      "|event_id|          event_name|sport_id|\n",
      "+--------+--------------------+--------+\n",
      "|       1|Basketball Men's ...|       1|\n",
      "|       2|Judo Men's Extra-...|       2|\n",
      "|       3|Football Men's Fo...|       3|\n",
      "|       4|Tug-Of-War Men's ...|       4|\n",
      "|       5|Speed Skating Wom...|       5|\n",
      "|       6|Speed Skating Wom...|       5|\n",
      "|       7|Cross Country Ski...|       6|\n",
      "|       8|Cross Country Ski...|       6|\n",
      "|       9|Cross Country Ski...|       6|\n",
      "|      10|Cross Country Ski...|       6|\n",
      "+--------+--------------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "OlympicEventsDF.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "GamesRDDSchema = StructType([\n",
    "    StructField('game_id', IntegerType(),False),\n",
    "    StructField('year', StringType(),False),\n",
    "    StructField('season', StringType(),False),\n",
    "    StructField('city', StringType(),False)\n",
    "])\n",
    "\n",
    "GamesDF = sqlContext.read.schema(GamesRDDSchema).option('header','true') \\\n",
    "    .csv(path+'juegos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+------+--------+\n",
      "|game_id|         year|season|    city|\n",
      "+-------+-------------+------+--------+\n",
      "|      1|  1896 Verano|  1896|  Verano|\n",
      "|      2|  1900 Verano|  1900|  Verano|\n",
      "|      3|  1904 Verano|  1904|  Verano|\n",
      "|      4|  1906 Verano|  1906|  Verano|\n",
      "|      5|  1908 Verano|  1908|  Verano|\n",
      "|      6|  1912 Verano|  1912|  Verano|\n",
      "|      7|  1920 Verano|  1920|  Verano|\n",
      "|      8|1924 Invierno|  1924|Invierno|\n",
      "|      9|  1924 Verano|  1924|  Verano|\n",
      "|     10|1928 Invierno|  1928|Invierno|\n",
      "+-------+-------------+------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "GamesDF.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResultsRDDSchema = StructType([\n",
    "    StructField('result_id', IntegerType(),False),\n",
    "    StructField('medal', StringType(),False),\n",
    "    StructField('athlete_id', IntegerType(),False),\n",
    "    StructField('game_id', IntegerType(),False),\n",
    "    StructField('event_id', IntegerType(),False)\n",
    "])\n",
    "\n",
    "ResultsDF = sqlContext.read.schema(ResultsRDDSchema).option('header','true') \\\n",
    "    .csv(path+'resultados.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(result_id=1, medal='NA', athlete_id=1, game_id=39, event_id=1),\n",
       " Row(result_id=2, medal='NA', athlete_id=2, game_id=49, event_id=2),\n",
       " Row(result_id=3, medal='NA', athlete_id=3, game_id=7, event_id=3),\n",
       " Row(result_id=4, medal='Gold', athlete_id=4, game_id=2, event_id=4),\n",
       " Row(result_id=5, medal='NA', athlete_id=5, game_id=36, event_id=5),\n",
       " Row(result_id=6, medal='NA', athlete_id=5, game_id=36, event_id=6),\n",
       " Row(result_id=7, medal='NA', athlete_id=5, game_id=38, event_id=5),\n",
       " Row(result_id=8, medal='NA', athlete_id=5, game_id=38, event_id=6),\n",
       " Row(result_id=9, medal='NA', athlete_id=5, game_id=40, event_id=5),\n",
       " Row(result_id=10, medal='NA', athlete_id=5, game_id=40, event_id=6)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResultsDF.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sport_id: integer (nullable = true)\n",
      " |-- sport_name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# A way to see the structure of the schema is with the next command:\n",
    "sportsDF.printSchema()\n",
    "# Because sometimes we won't have the schema details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- athlete_id: integer (nullable = false)\n",
      " |-- name: string (nullable = false)\n",
      " |-- gender: integer (nullable = false)\n",
      " |-- age: integer (nullable = false)\n",
      " |-- height: integer (nullable = false)\n",
      " |-- weight: float (nullable = false)\n",
      " |-- team_id: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AthleteDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To modify columns we use:\n",
    "# We also drop columns with drop command\n",
    "\n",
    "AthleteDF2 = AthleteDF.withColumnRenamed('gender','gender_athlete').drop('height')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- athlete_id: integer (nullable = false)\n",
      " |-- name: string (nullable = false)\n",
      " |-- gender_athlete: integer (nullable = false)\n",
      " |-- age: integer (nullable = false)\n",
      " |-- weight: float (nullable = false)\n",
      " |-- team_id: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AthleteDF2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries to work with SQL commands in Spark\n",
    "from pyspark.sql.functions import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Col function i to operate directly in the column header. it works differect \n",
    "# that a simple DF function\n",
    "# Col works only with a certain column (don't run over the entire dataframe)\n",
    "# Col created a list with the columns headers to operate with them.\n",
    "# In this case we use col to rename a column\n",
    "AthleteDF_select = AthleteDF2.select('athlete_id',\n",
    "                  'name',\n",
    "                  col('age').alias('PlayAge'),\n",
    "                  'team_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-------+-------+\n",
      "|athlete_id|                name|PlayAge|team_id|\n",
      "+----------+--------------------+-------+-------+\n",
      "|         1|           A Dijiang|     24|    199|\n",
      "|         2|            A Lamusi|     23|    199|\n",
      "|         3| Gunnar Nielsen Aaby|     24|    273|\n",
      "|         4|Edgar Lindenau Aabye|     34|    278|\n",
      "|         5|Christine Jacoba ...|     21|    705|\n",
      "|         6|     Per Knut Aaland|     31|   1096|\n",
      "|         7|        John Aalberg|     31|   1096|\n",
      "|         8|Cornelia Cor Aalt...|     18|    705|\n",
      "|         9|    Antti Sami Aalto|     26|    350|\n",
      "|        10|Einar Ferdinand E...|     26|    350|\n",
      "+----------+--------------------+-------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AthleteDF_select.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-------+-------+\n",
      "|athlete_id|                name|PlayAge|team_id|\n",
      "+----------+--------------------+-------+-------+\n",
      "|       224|     Mohamed AbdelEl|      0|    308|\n",
      "|       487|      Inni Aboubacar|      0|    721|\n",
      "|       226|Sanad Bushara Abd...|      0|   1003|\n",
      "|        58|    Georgi Abadzhiev|      0|    154|\n",
      "|       230|    Moustafa Abdelal|      0|    308|\n",
      "|       102|   Sayed Fahmy Abaza|      0|    308|\n",
      "|       260|  Ahmed Abdo Mustafa|      0|   1003|\n",
      "|       139|George Ioannis Abbot|      0|   1043|\n",
      "|       281|      S. Abdul Hamid|      0|    487|\n",
      "|       163|     Ismail Abdallah|      0|   1095|\n",
      "|       285|Talal Hassoun Abd...|      0|    497|\n",
      "|       173| Mohamed Abdel Fatah|      0|   1003|\n",
      "|       179|Ibrahim Saad Abde...|      0|   1003|\n",
      "|       378|     Angelik Abebame|      0|      0|\n",
      "|       294|Mohamed Ghulom Ab...|      0|     81|\n",
      "|       186| Mohamed Abdel Hafiz|      0|   1095|\n",
      "|       300|     A. Abdul Razzak|      0|    497|\n",
      "|       190| Ibrahim Abdel Hamid|      0|    308|\n",
      "|       301|Mohamed Abdul Razzak|      0|    497|\n",
      "|       209|Ibrahim Abdel Rahman|      0|   1095|\n",
      "+----------+--------------------+-------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sorting by PlayAge values in descending from:\n",
    "AthleteDF_select.sort('PlayAge').show()\n",
    "# We can see that there are some incorrect values with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid 0 values, we will use a filter with a condition (similar to WHERE in SQL)\n",
    "AthleteDF_filter = AthleteDF_select.filter(AthleteDF_select.PlayAge != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-------+-------+\n",
      "|athlete_id|                name|PlayAge|team_id|\n",
      "+----------+--------------------+-------+-------+\n",
      "|     71691|  Dimitrios Loundras|     10|    333|\n",
      "|     70616|          Liu Luyang|     11|    199|\n",
      "|    118925|Megan Olwen Deven...|     11|    413|\n",
      "|     52070|        Etsuko Inada|     11|    514|\n",
      "|     22411|Magdalena Cecilia...|     11|    413|\n",
      "|     40129|    Luigina Giavotti|     11|    507|\n",
      "|     47618|Sonja Henie Toppi...|     11|    742|\n",
      "|     76675|   Marcelle Matthews|     11|    967|\n",
      "|     37333|Carlos Bienvenido...|     11|    982|\n",
      "|     51268|      Beatrice Hutiu|     11|    861|\n",
      "|    126307|        Liana Vicens|     11|    825|\n",
      "|     48939|             Ho Gang|     12|    738|\n",
      "|     49142|        Jan Hoffmann|     12|    302|\n",
      "|     42835|   Werner Grieshofer|     12|     71|\n",
      "|     54620|Belita Gladys Lyn...|     12|    413|\n",
      "|     31203|Patricia Anne Pat...|     12|    967|\n",
      "|     43528|Antoinette Joyce ...|     12|    172|\n",
      "|     46578|        Diana Hatler|     12|    825|\n",
      "|     59727|Marika Kilius Zah...|     12|    399|\n",
      "|     40296|    Alain C. Giletti|     12|    362|\n",
      "+----------+--------------------+-------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can see that the youngest athlete in participated in olympic games was\n",
    "# a 10 years child.\n",
    "AthleteDF_filter.sort('PlayAge').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe JOIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- athlete_id: integer (nullable = false)\n",
      " |-- name: string (nullable = false)\n",
      " |-- gender: integer (nullable = false)\n",
      " |-- age: integer (nullable = false)\n",
      " |-- height: integer (nullable = false)\n",
      " |-- weight: float (nullable = false)\n",
      " |-- team_id: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First, we need to check the schema's structures\n",
    "AthleteDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- result_id: integer (nullable = true)\n",
      " |-- medal: string (nullable = true)\n",
      " |-- athlete_id: integer (nullable = true)\n",
      " |-- game_id: integer (nullable = true)\n",
      " |-- event_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ResultsDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- game_id: integer (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- season: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "GamesDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- event_id: integer (nullable = true)\n",
      " |-- event_name: string (nullable = true)\n",
      " |-- sport_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "OlympicEventsDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+-----+-------------+--------------------+\n",
      "|        athlete_name|PlayAge|medal|     PlayYear|     discipline_name|\n",
      "+--------------------+-------+-----+-------------+--------------------+\n",
      "|           A Dijiang|     24|   NA|  1992 Verano|Basketball Men's ...|\n",
      "|            A Lamusi|     23|   NA|  2012 Verano|Judo Men's Extra-...|\n",
      "| Gunnar Nielsen Aaby|     24|   NA|  1920 Verano|Football Men's Fo...|\n",
      "|Edgar Lindenau Aabye|     34| Gold|  1900 Verano|Tug-Of-War Men's ...|\n",
      "|Christine Jacoba ...|     21|   NA|1994 Invierno|Speed Skating Wom...|\n",
      "|Christine Jacoba ...|     21|   NA|1994 Invierno|Speed Skating Wom...|\n",
      "|Christine Jacoba ...|     21|   NA|1992 Invierno|Speed Skating Wom...|\n",
      "|Christine Jacoba ...|     21|   NA|1992 Invierno|Speed Skating Wom...|\n",
      "|Christine Jacoba ...|     21|   NA|1988 Invierno|Speed Skating Wom...|\n",
      "|Christine Jacoba ...|     21|   NA|1988 Invierno|Speed Skating Wom...|\n",
      "|     Per Knut Aaland|     31|   NA|1994 Invierno|Cross Country Ski...|\n",
      "|     Per Knut Aaland|     31|   NA|1994 Invierno|Cross Country Ski...|\n",
      "|     Per Knut Aaland|     31|   NA|1994 Invierno|Cross Country Ski...|\n",
      "|     Per Knut Aaland|     31|   NA|1994 Invierno|Cross Country Ski...|\n",
      "|     Per Knut Aaland|     31|   NA|1992 Invierno|Cross Country Ski...|\n",
      "|     Per Knut Aaland|     31|   NA|1992 Invierno|Cross Country Ski...|\n",
      "|     Per Knut Aaland|     31|   NA|1992 Invierno|Cross Country Ski...|\n",
      "|     Per Knut Aaland|     31|   NA|1992 Invierno|Cross Country Ski...|\n",
      "|        John Aalberg|     31|   NA|1994 Invierno|Cross Country Ski...|\n",
      "|        John Aalberg|     31|   NA|1994 Invierno|Cross Country Ski...|\n",
      "+--------------------+-------+-----+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for join parameters, the first one is the table we want to join (in this case ResultsDF)\n",
    "# next we need to introduce the condition (similar to JOIN - ON in SQL), and the kind of join (inner, left, etc)\n",
    "AthleteDF.join(\n",
    "                ResultsDF, \n",
    "                AthleteDF.athlete_id == ResultsDF.athlete_id,\n",
    "                'left'\n",
    "                ) \\\n",
    "         .join(\n",
    "                GamesDF,\n",
    "                ResultsDF.game_id == GamesDF.game_id,\n",
    "                'left'\n",
    "                ) \\\n",
    "         .join(\n",
    "                OlympicEventsDF,\n",
    "                ResultsDF.event_id == OlympicEventsDF.event_id,\n",
    "                'left'\n",
    "                ) \\\n",
    "         .select(\n",
    "                AthleteDF.name.alias('athlete_name'), \n",
    "                col('age').alias('PlayAge'),\n",
    "                'medal',\n",
    "                col('year').alias('PlayYear'),\n",
    "                OlympicEventsDF.event_name.alias('discipline_name')\n",
    "                ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+------------+\n",
      "| medal|team_name|country_name|\n",
      "+------+---------+------------+\n",
      "|  Gold| Zimbabwe|         ZIM|\n",
      "|  Gold| Zimbabwe|         ZIM|\n",
      "|  Gold| Zimbabwe|         ZIM|\n",
      "|Silver| Zimbabwe|         ZIM|\n",
      "|Silver| Zimbabwe|         ZIM|\n",
      "|  Gold| Zimbabwe|         ZIM|\n",
      "|  Gold| Zimbabwe|         ZIM|\n",
      "|  Gold| Zimbabwe|         ZIM|\n",
      "|  Gold| Zimbabwe|         ZIM|\n",
      "|  Gold| Zimbabwe|         ZIM|\n",
      "|  Gold| Zimbabwe|         ZIM|\n",
      "|  Gold| Zimbabwe|         ZIM|\n",
      "|  Gold| Zimbabwe|         ZIM|\n",
      "|  Gold| Zimbabwe|         ZIM|\n",
      "|  Gold| Zimbabwe|         ZIM|\n",
      "|  Gold| Zimbabwe|         ZIM|\n",
      "|Silver| Zimbabwe|         ZIM|\n",
      "|Bronze| Zimbabwe|         ZIM|\n",
      "|Silver| Zimbabwe|         ZIM|\n",
      "|  Gold| Zimbabwe|         ZIM|\n",
      "+------+---------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Platzi Challenge !!\n",
    "# Filtering result with medals\n",
    "# join with countries and and athletes\n",
    "# then sorting the results by a column in a descending form\n",
    "ResultsDF.filter(ResultsDF.medal != 'NA') \\\n",
    "    .join(\n",
    "           AthleteDF, \n",
    "           AthleteDF.athlete_id == ResultsDF.athlete_id,\n",
    "           'left'\n",
    "          ) \\\n",
    "    .join(\n",
    "           CountriesDF,\n",
    "           CountriesDF.team_id == AthleteDF.team_id,\n",
    "           'left'\n",
    "          ) \\\n",
    "    .select('medal','team_name','country_name') \\\n",
    "    .sort( col('country_name').desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a new table with more info.\n",
    "AthleteMedals = AthleteDF \\\n",
    "        .join(\n",
    "                ResultsDF,\n",
    "                ResultsDF.athlete_id == AthleteDF.athlete_id,\n",
    "                'left'\n",
    "             ) \\\n",
    "        .join(\n",
    "                GamesDF,\n",
    "                GamesDF.game_id == ResultsDF.game_id,\n",
    "                'left'\n",
    "             ) \\\n",
    "        .join(\n",
    "                CountriesDF,\n",
    "                CountriesDF.team_id == AthleteDF.team_id,\n",
    "                'left'\n",
    "             ) \\\n",
    "        .join(\n",
    "                OlympicEventsDF,\n",
    "                OlympicEventsDF.event_id == ResultsDF.event_id,\n",
    "                'left'\n",
    "             ) \\\n",
    "        .join(\n",
    "                sportsDF,\n",
    "                sportsDF.sport_id == OlympicEventsDF.sport_id,\n",
    "                'left'\n",
    "             ) \\\n",
    "        .select(\n",
    "                'country_name',\n",
    "                'year',\n",
    "                'medal',\n",
    "                OlympicEventsDF.event_name.alias('Subdiscipline_name'),\n",
    "                sportsDF.sport_name.alias('Discipline_name'),\n",
    "                AthleteDF.name,\n",
    "               )\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+-----+--------------------+---------------+--------------------+\n",
      "|country_name|       year|medal|  Subdiscipline_name|Discipline_name|                name|\n",
      "+------------+-----------+-----+--------------------+---------------+--------------------+\n",
      "|         BRU|2016 Verano|   NA|Athletics Women's...|      Athletics|Maizurah Abdul Rahim|\n",
      "|         BRU|2000 Verano|   NA|Shooting Men's Skeet|       Shooting|Jefri Kiko Bolkia...|\n",
      "|         BRU|1996 Verano|   NA|Shooting Men's Skeet|       Shooting|Jefri Kiko Bolkia...|\n",
      "|         BRU|2004 Verano|   NA|Athletics Men's 1...|      Athletics|     Jimmy Anak Ahar|\n",
      "|         BRU|2000 Verano|   NA|Athletics Men's 1...|      Athletics|         Haseri Asli|\n",
      "|         BRU|2016 Verano|   NA|Athletics Men's 1...|      Athletics|Mohamed Fakhri Is...|\n",
      "|         BRU|2012 Verano|   NA|Swimming Men's 20...|       Swimming|Anderson Chee Wei...|\n",
      "|         BRU|2012 Verano|   NA|Athletics Women's...|      Athletics|      Maziah Mahusin|\n",
      "|         BRU|2012 Verano|   NA|Athletics Men's 4...|      Athletics|Ak Hafiy Tajuddin...|\n",
      "|         BRU|2016 Verano|   NA|Badminton Men's S...|      Badminton| Woon Chai Jaspar Yu|\n",
      "+------------+-----------+-----+--------------------+---------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AthleteMedals.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #filtering only3 first places in the podium, Making a count() using groupby and sorting by year\n",
    "AthleteMedals2 = AthleteMedals.filter(AthleteMedals.medal != 'NA') \\\n",
    "    .sort('year') \\\n",
    "    .groupBy('country_name','year','Subdiscipline_name') \\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country_name: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- Subdiscipline_name: string (nullable = true)\n",
      " |-- count: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AthleteMedals2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+------------+------------------+\n",
      "|country_name|         year|Total Medals|    Average Medals|\n",
      "+------------+-------------+------------+------------------+\n",
      "|         NED|1992 Invierno|           4|1.3333333333333333|\n",
      "|         BEL|  2000 Verano|           7|               1.4|\n",
      "|         MAS|  2012 Verano|           2|               1.0|\n",
      "|         MGL|  2008 Verano|           5|              1.25|\n",
      "|         SWE|  1976 Verano|          10|               2.0|\n",
      "|         SUI|2014 Invierno|          29|3.2222222222222223|\n",
      "|         ETH|  2004 Verano|           7|              1.75|\n",
      "|         AUT|  1928 Verano|           5|              1.25|\n",
      "|         SYR|  1984 Verano|           1|               1.0|\n",
      "|         ITA|  1996 Verano|          69| 2.225806451612903|\n",
      "|         THA|  2008 Verano|           4|               1.0|\n",
      "|         URS|1984 Invierno|          56|               2.8|\n",
      "|         DEN|  1896 Verano|           6|               1.0|\n",
      "|         GRN|  2016 Verano|           1|               1.0|\n",
      "|         DEN|  1956 Verano|           6|               1.5|\n",
      "|         ARG|  2004 Verano|          49| 8.166666666666666|\n",
      "|         CHI|  1988 Verano|           1|               1.0|\n",
      "|         GBR|  1980 Verano|          49|              2.45|\n",
      "|         ITA|  1972 Verano|          25|            1.5625|\n",
      "|         UGA|  1980 Verano|           1|               1.0|\n",
      "+------------+-------------+------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# agg (agregate) function is the best way to make aggregations\n",
    "# We are making a sum column and an average column\n",
    "# totals will be groupby country and year\n",
    "AthleteMedals2.groupBy('country_name','year') \\\n",
    "    .agg(sum('count').alias('Total Medals'), \\\n",
    "    avg('count').alias('Average Medals')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal SQL Querys in Spark\n",
    "It is highly recommended to use SQL Context to build normal tables or dataframes, but for big tables and complex joins it's better use native Spark functions because in that way we will use less cluster power processing.\n",
    "SQL context is faster for consulting data but requires more power processing. For big data SQLContext is not worth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frist, we register a table as a temporal SQL table with this sintaxis:\n",
    "ResultsDF.registerTempTable('Results')\n",
    "AthleteDF.registerTempTable('Athlete')\n",
    "CountriesDF.registerTempTable('Countries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+------+---+------+------+-------+\n",
      "|athlete_id|                name|gender|age|height|weight|team_id|\n",
      "+----------+--------------------+------+---+------+------+-------+\n",
      "|         1|           A Dijiang|     1| 24|   180|  80.0|    199|\n",
      "|         2|            A Lamusi|     1| 23|   170|  60.0|    199|\n",
      "|         3| Gunnar Nielsen Aaby|     1| 24|     0|   0.0|    273|\n",
      "|         4|Edgar Lindenau Aabye|     1| 34|     0|   0.0|    278|\n",
      "|         5|Christine Jacoba ...|     2| 21|   185|  82.0|    705|\n",
      "+----------+--------------------+------+---+------+------+-------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---------+-----+----------+-------+--------+\n",
      "|result_id|medal|athlete_id|game_id|event_id|\n",
      "+---------+-----+----------+-------+--------+\n",
      "|        1|   NA|         1|     39|       1|\n",
      "|        2|   NA|         2|     49|       2|\n",
      "|        3|   NA|         3|      7|       3|\n",
      "|        4| Gold|         4|      2|       4|\n",
      "|        5|   NA|         5|     36|       5|\n",
      "+---------+-----+----------+-------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------+--------------------+------------+\n",
      "|team_id|           team_name|country_name|\n",
      "+-------+--------------------+------------+\n",
      "|      1|         30. Februar|         AUT|\n",
      "|      2|A North American ...|         MEX|\n",
      "|      3|           Acipactli|         MEX|\n",
      "|      4|             Acturus|         ARG|\n",
      "|      5|         Afghanistan|         AFG|\n",
      "+-------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# With SQL Context we can run traditional SQL querys in our temporal tables:\n",
    "sqlContext.sql('SELECT * FROM Athlete').show(5)\n",
    "sqlContext.sql('SELECT * FROM Results').show(5)\n",
    "sqlContext.sql('SELECT * FROM Countries').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+------------+\n",
      "| medal|team_name|country_name|\n",
      "+------+---------+------------+\n",
      "|  Gold| Zimbabwe|         ZIM|\n",
      "|  Gold| Zimbabwe|         ZIM|\n",
      "|  Gold| Zimbabwe|         ZIM|\n",
      "|  Gold| Zimbabwe|         ZIM|\n",
      "|  Gold| Zimbabwe|         ZIM|\n",
      "|Bronze| Zimbabwe|         ZIM|\n",
      "|  Gold| Zimbabwe|         ZIM|\n",
      "|  Gold| Zimbabwe|         ZIM|\n",
      "|  Gold| Zimbabwe|         ZIM|\n",
      "|Silver| Zimbabwe|         ZIM|\n",
      "|  Gold| Zimbabwe|         ZIM|\n",
      "|  Gold| Zimbabwe|         ZIM|\n",
      "|Silver| Zimbabwe|         ZIM|\n",
      "|  Gold| Zimbabwe|         ZIM|\n",
      "|Silver| Zimbabwe|         ZIM|\n",
      "|Silver| Zimbabwe|         ZIM|\n",
      "|  Gold| Zimbabwe|         ZIM|\n",
      "|  Gold| Zimbabwe|         ZIM|\n",
      "|  Gold| Zimbabwe|         ZIM|\n",
      "|  Gold| Zimbabwe|         ZIM|\n",
      "+------+---------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# JOINs with SQL\n",
    "sqlContext.sql(\"\"\"\n",
    "                SELECT  r.medal,\n",
    "                        c.team_name,\n",
    "                        c.country_name\n",
    "                FROM Results AS r\n",
    "                JOIN Athlete AS a\n",
    "                ON r.athlete_id = a.athlete_id\n",
    "                JOIN Countries AS c\n",
    "                ON c.team_id = a.team_id\n",
    "                WHERE medal <> 'NA'\n",
    "                ORDER BY country_name DESC\n",
    "                \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.66:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Dataframes</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local appName=Dataframes>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deportista_id,nombre,genero,edad,altura,peso,equipo_id\n",
      "1,A Dijiang,1,24,180,80,199\n",
      "2,A Lamusi,1,23,170,60,199\n",
      "3,Gunnar Nielsen Aaby,1,24,,,273\n",
      "4,Edgar Lindenau Aabye,1,34,,,278\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 /home/lastorder/Documents/curso-apache-spark-platzi/files/deportistaError.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the RDD from a .csv file\n",
    "athleteErrorRDD = spark.textFile(path+'deportistaError.csv')  \\\n",
    "    .map(lambda l: l.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the header of the RDD with the function we defined\n",
    "athleteErrorRDD = athleteErrorRDD.mapPartitionsWithIndex(removeHeader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', 'A Dijiang', '1', '24', '180', '80', '199'],\n",
       " ['2', 'A Lamusi', '1', '23', '170', '60', '199']]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we have our RDD without header\n",
    "athleteErrorRDD.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maping the values of the RDD\n",
    "# All with string type (l[x])\n",
    "athleteErrorRDD = athleteErrorRDD.map(lambda l:\n",
    "                                     (l[0],\n",
    "                                      l[1],\n",
    "                                      l[2],\n",
    "                                      l[3],\n",
    "                                      l[4],\n",
    "                                      l[5],\n",
    "                                      l[6])\n",
    "                                     )\n",
    "\n",
    "# Genering the schema\n",
    "\n",
    "schema = StructType([\n",
    "    StructField('athlete_id', StringType(), False),\n",
    "    StructField('name', StringType(), False),\n",
    "    StructField('gender', StringType(), False),\n",
    "    StructField('age', StringType(), False),\n",
    "    StructField('height', StringType(), False),\n",
    "    StructField('weight', StringType(), False),\n",
    "    StructField('team_id', StringType(), False),\n",
    "])\n",
    "\n",
    "# Creating the dataframe\n",
    "\n",
    "athleteErrorDF = sqlContext.createDataFrame(athleteErrorRDD, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+------+---+------+------+-------+\n",
      "|athlete_id|                name|gender|age|height|weight|team_id|\n",
      "+----------+--------------------+------+---+------+------+-------+\n",
      "|         1|           A Dijiang|     1| 24|   180|    80|    199|\n",
      "|         2|            A Lamusi|     1| 23|   170|    60|    199|\n",
      "|         3| Gunnar Nielsen Aaby|     1| 24|      |      |    273|\n",
      "|         4|Edgar Lindenau Aabye|     1| 34|      |      |    278|\n",
      "|         5|Christine Jacoba ...|     2| 21|   185|    82|    705|\n",
      "|         6|     Per Knut Aaland|     1| 31|   188|    75|   1096|\n",
      "|         7|        John Aalberg|     1| 31|   183|    72|   1096|\n",
      "|         8|\"Cornelia \"\"Cor\"\"...|     2| 18|   168|      |    705|\n",
      "|         9|    Antti Sami Aalto|     1| 26|   186|    96|    350|\n",
      "|        10|\"Einar Ferdinand ...|     1| 26|      |      |    350|\n",
      "|        11|  Jorma Ilmari Aalto|     1| 22|   182|  76.5|    350|\n",
      "|        12|   Jyri Tapani Aalto|     1| 31|   172|    70|    350|\n",
      "|        13|  Minna Maarit Aalto|     2| 30|   159|  55.5|    350|\n",
      "|        14|Pirjo Hannele Aal...|     2| 32|   171|    65|    350|\n",
      "|        15|Arvo Ossian Aaltonen|     1| 22|      |      |    350|\n",
      "|        16|Juhamatti Tapio A...|     1| 28|   184|    85|    350|\n",
      "|        17|Paavo Johannes Aa...|     1| 28|   175|    64|    350|\n",
      "|        18|Timo Antero Aaltonen|     1| 31|   189|   130|    350|\n",
      "|        19|Win Valdemar Aalt...|     1| 54|      |      |    350|\n",
      "|        20|  Kjetil Andr Aamodt|     1| 20|   176|    85|    742|\n",
      "+----------+--------------------+------+---+------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "athleteErrorDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(z)>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Libraries to create UDFs\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "# Creating python function\n",
    "# this function transform to INT a column and return NULL if there's no value.\n",
    "def convertionINT(value):\n",
    "    return int(value) if len(value) > 0 else None\n",
    "\n",
    "# Creating the UDF using the previous python function\n",
    "convertionINT_udf = udf(lambda z: convertionINT(z), IntegerType())\n",
    "\n",
    "# To register the UDF in Spark:\n",
    "# Parameters: the name it will take in Spark the UDF, the UDF function.\n",
    "sqlContext.udf.register('convertINT_udf', convertionINT_udf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|height_UDF|\n",
      "+----------+\n",
      "|       180|\n",
      "|       170|\n",
      "|      null|\n",
      "|      null|\n",
      "|       185|\n",
      "|       188|\n",
      "|       183|\n",
      "|       168|\n",
      "|       186|\n",
      "|      null|\n",
      "|       182|\n",
      "|       172|\n",
      "|       159|\n",
      "|       171|\n",
      "|      null|\n",
      "|       184|\n",
      "|       175|\n",
      "|       189|\n",
      "|      null|\n",
      "|       176|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying the UDF on our Dataframe to convert a string column to INT column\n",
    "athleteErrorDF.select(convertionINT_udf('height').alias('height_UDF')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries for storage management\n",
    "from pyspark.storagelevel import StorageLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To check if a RDD o DF are storage in memory we can use:\n",
    "AthleteMedals2.is_cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[228] at javaToPython at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Every time that you make an action, and use a table that is no saving in memory or disk\n",
    "# Spark run that process to use the values, that means you process will take more time and use more\n",
    "# processing from our cluster.\n",
    "\n",
    "# To save in cache a RDD or dataframe:\n",
    "# We use .rdd because is and primitive function of the RDD structure\n",
    "AthleteMedals2.rdd.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StorageLevel(False, True, False, False, 1)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see what kind of saving is using for that table, we use getStorageLevel\n",
    "AthleteMedals2.rdd.getStorageLevel()\n",
    "\n",
    "# Parameters are: (useDisk, useMemory, useOffHeap, deserialized, replication).\n",
    "# To check details go to official Spark documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[228] at javaToPython at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To agregrate persistency to our data:\n",
    "\n",
    "# Before that we need to erase the table from memory, because we already save it in memory:\n",
    "AthleteMedals2.rdd.unpersist()\n",
    "\n",
    "\n",
    "# Check the complete list of Storage Levels in Spark Documentation\n",
    "# Here we want to save the data in memory and disk with replicating the data 2 times.\n",
    "AthleteMedals2.rdd.persist(StorageLevel.MEMORY_AND_DISK_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For create our own partitional Level\n",
    "# For good practices we want to replicate the data 3 times to minimize duplicity errors (by statistics)\n",
    "# Parameters are: (useDisk, useMemory, useOffHeap, deserialized, replication).\n",
    "\n",
    "StorageLevel.MEMORY_AND_DISK_3 = StorageLevel(True, True, False, False, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[228] at javaToPython at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the persistance we created\n",
    "\n",
    "AthleteMedals2.rdd.unpersist()\n",
    "AthleteMedals2.rdd.persist(StorageLevel.MEMORY_AND_DISK_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
