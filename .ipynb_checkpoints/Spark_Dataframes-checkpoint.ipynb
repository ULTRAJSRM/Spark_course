{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframes\n",
    "**By Jorge S. Ruiz**\n",
    " - This is an introduction about how to use Dataframes in Spark.\n",
    " - Dataframes can be used as SQL tables.\n",
    " - Dataframes have better optimization because they use Catalyst as query optimization and Tugsten as execution engine.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a dataframe from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Libraries for Datatypes (dataframes)\n",
    "from pyspark.sql.types import StructType, StructField \n",
    "from pyspark.sql.types import IntegerType, StringType, FloatType\n",
    "from pyspark.sql.types import Row\n",
    "\n",
    "# Library for SQL\n",
    "from pyspark.sql import SQLContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing Spark\n",
    "spark = SparkContext(master='local', appName='Dataframes')\n",
    "# Initializing SQL Context\n",
    "sqlContext = SQLContext(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deporte.csv\t deportistaError.csv  modelo_relacional.jpg\n",
      "deportista2.csv  evento.csv\t      paises.csv\n",
      "deportista.csv\t juegos.csv\t      resultados.csv\n"
     ]
    }
   ],
   "source": [
    "!ls /home/lastorder/Documents/curso-apache-spark-platzi/files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",nombre_juego,annio,temporada,ciudad\n",
      "1,1896 Verano,1896,Verano,Athina\n",
      "2,1900 Verano,1900,Verano,Paris\n",
      "3,1904 Verano,1904,Verano,St. Louis\n"
     ]
    }
   ],
   "source": [
    "# Linux command to check the file content\n",
    "!head -n 4 /home/lastorder/Documents/curso-apache-spark-platzi/files/juegos.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the PATH to csv files.\n",
    "path = '/home/lastorder/Documents/curso-apache-spark-platzi/files/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to create a schema with the information of the columns:\n",
    "# Struct file helpus to indicate the parameters of the columns of the DF\n",
    "# The fields are, name of the column, datatype and if the column is an optional field.\n",
    "# False indicates that the column is a necessary field and true indicates that is optional.\n",
    "\n",
    "gameSchema = StructType([\n",
    "    StructField('game_id',IntegerType(),False),\n",
    "    StructField('year',StringType(),False),\n",
    "    StructField('season',StringType(),False),\n",
    "    StructField('city',StringType(),False)\n",
    "])\n",
    "\n",
    "# Now we can create the dataframe using our previous Schema.\n",
    "\n",
    "gameDF = sqlContext.read.schema(gameSchema).option('header','true') \\\n",
    "    .csv(path+'juegos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+------+--------+\n",
      "|game_id|         year|season|    city|\n",
      "+-------+-------------+------+--------+\n",
      "|      1|  1896 Verano|  1896|  Verano|\n",
      "|      2|  1900 Verano|  1900|  Verano|\n",
      "|      3|  1904 Verano|  1904|  Verano|\n",
      "|      4|  1906 Verano|  1906|  Verano|\n",
      "|      5|  1908 Verano|  1908|  Verano|\n",
      "|      6|  1912 Verano|  1912|  Verano|\n",
      "|      7|  1920 Verano|  1920|  Verano|\n",
      "|      8|1924 Invierno|  1924|Invierno|\n",
      "|      9|  1924 Verano|  1924|  Verano|\n",
      "|     10|1928 Invierno|  1928|Invierno|\n",
      "+-------+-------------+------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In dataframes we can use \"show\" to obtain a better data visualization\n",
    "gameDF.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.66:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Dataframes</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local appName=Dataframes>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To access to Spark UI console, we use just \"spark\" command and click on Spark UI\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Extract from RDDs Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting 2 RDDs, the first one contains the header and the second one contains the data.\n",
    "OlimpicAthleteRDD = spark.textFile(path+'deportista.csv').map(lambda l : l.split(','))\n",
    "OlimpicAthleteRDD2 = spark.textFile(path+'deportista2.csv').map(lambda l : l.split(','))\n",
    "\n",
    "# To make a union between the RDDs we can use:\n",
    "OlimpicAthleteRDD = OlimpicAthleteRDD.union(OlimpicAthleteRDD2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135572"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To make sure that the data is not corrupted, we can use count() to verify that spark is working correctly\n",
    "# with that data\n",
    "OlimpicAthleteRDD.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['deportista_id', 'nombre', 'genero', 'edad', 'altura', 'peso', 'equipo_id'],\n",
       " ['1', 'A Dijiang', '1', '24', '180', '80', '199'],\n",
       " ['2', 'A Lamusi', '1', '23', '170', '60', '199'],\n",
       " ['3', 'Gunnar Nielsen Aaby', '1', '24', '0', '0', '273'],\n",
       " ['4', 'Edgar Lindenau Aabye', '1', '34', '0', '0', '278']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see the first 10 rows of the RDD, we use top function (similar to SQL)\n",
    "OlimpicAthleteRDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the header of the RDD\n",
    "# 'iter' function, returns all values of we process in the function\n",
    "\n",
    "def removeHeader(index, iterator):\n",
    "    \"\"\"A fuction that removes the header from a dataset or RDD\"\"\"\n",
    "    return iter(list(iterator)[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We map the RDD assigning a index (this maps rows and columns per index)\n",
    "# Now we can use a function that will take action in all rows and columns on the RDD.\n",
    "OlimpicAthleteRDD_clean = OlimpicAthleteRDD.mapPartitionsWithIndex(removeHeader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', 'A Dijiang', '1', '24', '180', '80', '199'],\n",
       " ['2', 'A Lamusi', '1', '23', '170', '60', '199'],\n",
       " ['3', 'Gunnar Nielsen Aaby', '1', '24', '0', '0', '273'],\n",
       " ['4', 'Edgar Lindenau Aabye', '1', '34', '0', '0', '278'],\n",
       " ['5', 'Christine Jacoba Aaftink', '2', '21', '185', '82', '705']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see if the header is gone\n",
    "OlimpicAthleteRDD_clean.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To transform the values of the RDD\n",
    "# For that we are goint to make a mapping\n",
    "\n",
    "OlimpicAthleteRDD_clean = OlimpicAthleteRDD_clean.map(lambda l: (\n",
    "    int(l[0]),\n",
    "    l[1],\n",
    "    int(l[2]),\n",
    "    int(l[3]),\n",
    "    int(l[4]),\n",
    "    float(l[5]),\n",
    "    int(l[6])    \n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We ned to define a new Schema:\n",
    "\n",
    "schema = StructType([\n",
    "    StructField('athlete_id', IntegerType(),False),\n",
    "    StructField('name', StringType(),False),\n",
    "    StructField('gender', IntegerType(),False),\n",
    "    StructField('age', IntegerType(),False),\n",
    "    StructField('height', IntegerType(),False),\n",
    "    StructField('weight', FloatType(),False),\n",
    "    StructField('team_id', IntegerType(),False),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe with sqlContext, using an existing RDD and a Schema\n",
    "AthleteDF = sqlContext.createDataFrame(OlimpicAthleteRDD_clean, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+------+---+------+------+-------+\n",
      "|athlete_id|                name|gender|age|height|weight|team_id|\n",
      "+----------+--------------------+------+---+------+------+-------+\n",
      "|         1|           A Dijiang|     1| 24|   180|  80.0|    199|\n",
      "|         2|            A Lamusi|     1| 23|   170|  60.0|    199|\n",
      "|         3| Gunnar Nielsen Aaby|     1| 24|     0|   0.0|    273|\n",
      "|         4|Edgar Lindenau Aabye|     1| 34|     0|   0.0|    278|\n",
      "|         5|Christine Jacoba ...|     2| 21|   185|  82.0|    705|\n",
      "|         6|     Per Knut Aaland|     1| 31|   188|  75.0|   1096|\n",
      "|         7|        John Aalberg|     1| 31|   183|  72.0|   1096|\n",
      "|         8|Cornelia Cor Aalt...|     2| 18|   168|   0.0|    705|\n",
      "|         9|    Antti Sami Aalto|     1| 26|   186|  96.0|    350|\n",
      "|        10|Einar Ferdinand E...|     1| 26|     0|   0.0|    350|\n",
      "+----------+--------------------+------+---+------+------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To prove everything is correct with our new DF, we can use show function\n",
    "AthleteDF.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(athlete_id=1, name='A Dijiang', gender=1, age=24, height=180, weight=80.0, team_id=199),\n",
       " Row(athlete_id=2, name='A Lamusi', gender=1, age=23, height=170, weight=60.0, team_id=199),\n",
       " Row(athlete_id=3, name='Gunnar Nielsen Aaby', gender=1, age=24, height=0, weight=0.0, team_id=273),\n",
       " Row(athlete_id=4, name='Edgar Lindenau Aabye', gender=1, age=34, height=0, weight=0.0, team_id=278),\n",
       " Row(athlete_id=5, name='Christine Jacoba Aaftink', gender=2, age=21, height=185, weight=82.0, team_id=705),\n",
       " Row(athlete_id=6, name='Per Knut Aaland', gender=1, age=31, height=188, weight=75.0, team_id=1096),\n",
       " Row(athlete_id=7, name='John Aalberg', gender=1, age=31, height=183, weight=72.0, team_id=1096),\n",
       " Row(athlete_id=8, name='Cornelia Cor Aalten Strannood ', gender=2, age=18, height=168, weight=0.0, team_id=705),\n",
       " Row(athlete_id=9, name='Antti Sami Aalto', gender=1, age=26, height=186, weight=96.0, team_id=350),\n",
       " Row(athlete_id=10, name='Einar Ferdinand Einari Aalto', gender=1, age=26, height=0, weight=0.0, team_id=350)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see the explicit values without format we use \"take\" function\n",
    "AthleteDF.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating another Dataframe from RDD\n",
    "CountriesRDD = spark.textFile(path+\"paises.csv\")\\\n",
    "    .map(lambda line : line.split(\",\"))\n",
    "\n",
    "CountriesRDD = CountriesRDD.mapPartitionsWithIndex(removeHeader)\n",
    "\n",
    "\n",
    "CountriesRDD = CountriesRDD.map(lambda l: (\n",
    "    int(l[0]),\n",
    "    l[1],\n",
    "    l[2]\n",
    "))\n",
    "\n",
    "CountriesSchema = StructType([\n",
    "    StructField('team_id', IntegerType(),False),\n",
    "    StructField('team_name', StringType(),False),\n",
    "    StructField('country_name', StringType(),False)\n",
    "])\n",
    "\n",
    "CountriesDF = sqlContext.createDataFrame(CountriesRDD, CountriesSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------------+\n",
      "|team_id|           team_name|country_name|\n",
      "+-------+--------------------+------------+\n",
      "|      1|         30. Februar|         AUT|\n",
      "|      2|A North American ...|         MEX|\n",
      "|      3|           Acipactli|         MEX|\n",
      "|      4|             Acturus|         ARG|\n",
      "|      5|         Afghanistan|         AFG|\n",
      "|      6|            Akatonbo|         IRL|\n",
      "|      7|            Alain IV|         SUI|\n",
      "|      8|             Albania|         ALB|\n",
      "|      9|              Alcaid|         POR|\n",
      "|     10|            Alcyon-6|         FRA|\n",
      "+-------+--------------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CountriesDF.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Dataframefrom csv with a schema (without using an RDD)\n",
    "OlympicSportsRDDSchema = StructType([\n",
    "    StructField('sport_id', IntegerType(),False),\n",
    "    StructField('sport_name', StringType(),False)\n",
    "])\n",
    "\n",
    "sportsDF = sqlContext.read.schema(OlympicSportsRDDSchema).option('header','true') \\\n",
    "    .csv(path+'deporte.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|sport_id|          sport_name|\n",
      "+--------+--------------------+\n",
      "|       1|          Basketball|\n",
      "|       2|                Judo|\n",
      "|       3|            Football|\n",
      "|       4|          Tug-Of-War|\n",
      "|       5|       Speed Skating|\n",
      "|       6|Cross Country Skiing|\n",
      "|       7|           Athletics|\n",
      "|       8|          Ice Hockey|\n",
      "|       9|            Swimming|\n",
      "|      10|           Badminton|\n",
      "+--------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sportsDF.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the same way, we can create as many datasets as we want.\n",
    "# All we need is to define an schema and import the csv file.\n",
    "EventsRDDSchema = StructType([\n",
    "    StructField('event_id', IntegerType(),False),\n",
    "    StructField('event_name', StringType(),False),\n",
    "    StructField('sport_id', IntegerType(),False)\n",
    "])\n",
    "\n",
    "OlympicEventsDF = sqlContext.read.schema(EventsRDDSchema).option('header','true') \\\n",
    "    .csv(path+'evento.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------+\n",
      "|event_id|          event_name|sport_id|\n",
      "+--------+--------------------+--------+\n",
      "|       1|Basketball Men's ...|       1|\n",
      "|       2|Judo Men's Extra-...|       2|\n",
      "|       3|Football Men's Fo...|       3|\n",
      "|       4|Tug-Of-War Men's ...|       4|\n",
      "|       5|Speed Skating Wom...|       5|\n",
      "|       6|Speed Skating Wom...|       5|\n",
      "|       7|Cross Country Ski...|       6|\n",
      "|       8|Cross Country Ski...|       6|\n",
      "|       9|Cross Country Ski...|       6|\n",
      "|      10|Cross Country Ski...|       6|\n",
      "+--------+--------------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "OlympicEventsDF.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "GamesRDDSchema = StructType([\n",
    "    StructField('game_id', IntegerType(),False),\n",
    "    StructField('year', StringType(),False),\n",
    "    StructField('season', StringType(),False),\n",
    "    StructField('city', StringType(),False)\n",
    "])\n",
    "\n",
    "GamesDF = sqlContext.read.schema(GamesRDDSchema).option('header','true') \\\n",
    "    .csv(path+'juegos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+------+--------+\n",
      "|game_id|         year|season|    city|\n",
      "+-------+-------------+------+--------+\n",
      "|      1|  1896 Verano|  1896|  Verano|\n",
      "|      2|  1900 Verano|  1900|  Verano|\n",
      "|      3|  1904 Verano|  1904|  Verano|\n",
      "|      4|  1906 Verano|  1906|  Verano|\n",
      "|      5|  1908 Verano|  1908|  Verano|\n",
      "|      6|  1912 Verano|  1912|  Verano|\n",
      "|      7|  1920 Verano|  1920|  Verano|\n",
      "|      8|1924 Invierno|  1924|Invierno|\n",
      "|      9|  1924 Verano|  1924|  Verano|\n",
      "|     10|1928 Invierno|  1928|Invierno|\n",
      "+-------+-------------+------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "GamesDF.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResultsRDDSchema = StructType([\n",
    "    StructField('result_id', IntegerType(),False),\n",
    "    StructField('medal', StringType(),False),\n",
    "    StructField('athlete_id', IntegerType(),False),\n",
    "    StructField('game_id', IntegerType(),False),\n",
    "    StructField('event_id', IntegerType(),False)\n",
    "])\n",
    "\n",
    "ResultsDF = sqlContext.read.schema(ResultsRDDSchema).option('header','true') \\\n",
    "    .csv(path+'resultados.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(result_id=1, medal='NA', athlete_id=1, game_id=39, event_id=1),\n",
       " Row(result_id=2, medal='NA', athlete_id=2, game_id=49, event_id=2),\n",
       " Row(result_id=3, medal='NA', athlete_id=3, game_id=7, event_id=3),\n",
       " Row(result_id=4, medal='Gold', athlete_id=4, game_id=2, event_id=4),\n",
       " Row(result_id=5, medal='NA', athlete_id=5, game_id=36, event_id=5),\n",
       " Row(result_id=6, medal='NA', athlete_id=5, game_id=36, event_id=6),\n",
       " Row(result_id=7, medal='NA', athlete_id=5, game_id=38, event_id=5),\n",
       " Row(result_id=8, medal='NA', athlete_id=5, game_id=38, event_id=6),\n",
       " Row(result_id=9, medal='NA', athlete_id=5, game_id=40, event_id=5),\n",
       " Row(result_id=10, medal='NA', athlete_id=5, game_id=40, event_id=6)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResultsDF.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
